{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CP_APR, CP_ALS, HOSVD, & TUCKER_ALS Profiling\n",
    "Outputting Profiling Files and Using Visualization with `gprof2dot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import glob\n",
    "import os\n",
    "import pstats\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from pyttb import cp_als, cp_apr, hosvd, import_data, sptensor, tensor, tucker_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_algorithm_func(algorithm_name: str) -> Optional[Callable]:\n",
    "    \"\"\"\n",
    "    Returns the corresponding function for the user-supplied algorithm name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    algorithm_name:\n",
    "        The algorithm to profile: 'cp_apr', 'cp_als', 'tucker_als', or 'hosvd'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alg_func:\n",
    "        The function corresponding to the algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # input validation\n",
    "    func_handler = {\n",
    "        \"cp_apr\": cp_apr,\n",
    "        \"cp_als\": cp_als,\n",
    "        \"tucker_als\": tucker_als,\n",
    "        \"hosvd\": hosvd,\n",
    "    }\n",
    "\n",
    "    alg_func = func_handler.get(algorithm_name.lower())\n",
    "    if alg_func is None:\n",
    "        raise ValueError(f\"'{algorithm_name}' is not a recognized algorithm.\")\n",
    "    return alg_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_alg(\n",
    "    alg_func: Callable,\n",
    "    input_tensor: Union[sptensor, tensor],\n",
    "    test_file: str,\n",
    "    algorithm_name: str,\n",
    "    label: Optional[str] = None,\n",
    "    **params: Optional[Dict[str, Union[int, float]]],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Profiles the performance of the specified algorithm and prints the statistics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alg_func:\n",
    "        The function to profile.\n",
    "    input_tensor:\n",
    "        The input data tensor provided to the alg_func.\n",
    "    test_file:\n",
    "        The name of the tensor file.\n",
    "    algorithm_name:\n",
    "        The name of the user-supplied algorithm.\n",
    "    label:\n",
    "        The user-supplied label to distinguish a test run.\n",
    "    params:\n",
    "        Paramters passed to the algorithm function.\n",
    "        'rank' may be given to the CP algorithms; 'tol' and 'verbosity' to hosvd.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize a cProfile object and start collecting profiling data.\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "\n",
    "    try:\n",
    "        alg_func(input_tensor, **params)\n",
    "    except Exception as e:\n",
    "        print(\n",
    "            f\"Error when running {algorithm_name} on {os.path.basename(test_file)}: {type(e).__name__}: {e}\"\n",
    "        )\n",
    "    finally:\n",
    "        # stop collecting data, and send data to Stats object and sort\n",
    "        profiler.disable()\n",
    "\n",
    "        # save profiling ouput to sub-directory specific to the function being tested.\n",
    "        output_directory = f\"./pstats_files/{algorithm_name}\"\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)  # create directory if it doesn't exist\n",
    "\n",
    "        # from 'foo_tensor_10_4.tns' obtain 'foo_tensor_10_4'\n",
    "        tf_basename_without_tns_ext = os.path.basename(test_file).split(\".\")[0]\n",
    "        identifier = label if label else algorithm_name\n",
    "        output_file = (\n",
    "            f\"{output_directory}/{tf_basename_without_tns_ext}_{identifier}.pstats\"\n",
    "        )\n",
    "\n",
    "        # write profiling results to new file in output_directory.\n",
    "        profiler.dump_stats(output_file)\n",
    "\n",
    "        print(\n",
    "            f\"Profiling stats for '{algorithm_name}' on '{os.path.basename(test_file)}' saved to '{output_file}'\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(\n",
    "    test_files: List[str],\n",
    "    ranks: List[int],\n",
    "    algorithm_name: str,\n",
    "    label: Optional[str] = None,\n",
    "    **params: Optional[Dict[str, Union[int, float]]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Profiles the performance of the cp and Tucker algorithms with a set of tensors from test_files and ranks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_files:\n",
    "        A list of strings representing the file paths to the test tensors.\n",
    "    ranks:\n",
    "        A list of integers representing the tensor testing ranks.\n",
    "    algorithm_name:\n",
    "        The algorithm to profile. Should be either 'cp_apr' or 'cp_als'.\n",
    "    label:\n",
    "        The user-supplied label to distinguish a test run. This will be used in the output file name.\n",
    "    params:\n",
    "        Paramters passed to the algorithm function.\n",
    "        'rank' may be given to the CP algorithms; 'tol' and 'verbosity' to hosvd.\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain the appropriate function.\n",
    "    alg_func = get_algorithm_func(algorithm_name)\n",
    "\n",
    "    # choose only 'integer' files for cp_apr.\n",
    "    if algorithm_name == \"cp_apr\":\n",
    "        test_files = [tf for tf in test_files if \"integer\" in tf]\n",
    "    # TODO: bypassing a \"TypeError: unsupported operand type(s) for ** or pow(): 'sptensor' and 'int'.\"\n",
    "    if algorithm_name == \"hosvd\":\n",
    "        test_files = [tf for tf in test_files if \"sparse\" not in tf]\n",
    "\n",
    "    for test_file in test_files:\n",
    "        print(\"*\" * 80)\n",
    "        try:\n",
    "            input_tensor = import_data(test_file)  # Load the tensor.\n",
    "            if algorithm_name != \"hosvd\":\n",
    "                # test across ranks for non-hosvd algos, since hosvd doesn't accept 'rank'.\n",
    "                for rank in ranks:\n",
    "                    # load the rank parameter to the testing algorithm's params\n",
    "                    params[\"rank\"] = rank\n",
    "                    profile_alg(\n",
    "                        alg_func,\n",
    "                        input_tensor,\n",
    "                        test_file,\n",
    "                        algorithm_name,\n",
    "                        label,\n",
    "                        **params,\n",
    "                    )\n",
    "            else:\n",
    "                profile_alg(\n",
    "                    alg_func, input_tensor, test_file, algorithm_name, label, **params\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error when testing {os.path.basename(test_file)} for Algorithm = {algorithm_name}: {type(e).__name__}: {e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_images():\n",
    "    \"\"\"Gathers all pstats files and renders pngs for inspection\"\"\"\n",
    "    stats_files = Path(\".\").glob(\"**/*.pstats\")\n",
    "    for a_file in stats_files:\n",
    "        algorithm = a_file.parts[-2]\n",
    "        experiment_name = a_file.stem\n",
    "        print(f\"For {algorithm}: generating {experiment_name}\")\n",
    "        Path(f\"./gprof2dot_images/{algorithm}\").mkdir(parents=True, exist_ok=True)\n",
    "        subprocess.run(\n",
    "            f\"gprof2dot -f pstats {a_file} |\"\n",
    "            f\" dot -Tpng -o ./gprof2dot_images/{algorithm}/{experiment_name}.png\",\n",
    "            shell=True,\n",
    "            check=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [2, 3, 4]\n",
    "test_files = glob.glob(\"data/*.tns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"cp_apr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"cp_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"tucker_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"hosvd\", tol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CP_APR**: Decreased maxiters and maxinneriters, differing input algorithms, and labeling keyword.\n",
    "\n",
    "`cp_apr`'s default parameters are:\n",
    "- **algorithm** = \"mu\"\n",
    "- **stoptol** = 1e-4\n",
    "- **maxiters** = 1000\n",
    "- **maxinneriters** = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(\n",
    "    test_files,\n",
    "    ranks,\n",
    "    \"cp_apr\",\n",
    "    algorithm=\"mu\",\n",
    "    label=\"mu_5iters\",\n",
    "    maxiters=5,\n",
    "    maxinneriters=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(\n",
    "    test_files,\n",
    "    ranks,\n",
    "    \"cp_apr\",\n",
    "    algorithm=\"pdnr\",\n",
    "    label=\"pdnr_maxiter5_maxinner5\",\n",
    "    maxiters=5,\n",
    "    maxinneriters=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(\n",
    "    test_files,\n",
    "    ranks,\n",
    "    \"cp_apr\",\n",
    "    algorithm=\"pqnr\",\n",
    "    label=\"pqnr\",\n",
    "    maxiters=5,\n",
    "    maxinneriters=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CP_ALS**: Decreased maxiters.\n",
    "`cp_als`'s default parameters are:\n",
    "- **stoptol** = 1e-4\n",
    "- **maxiters** = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"cp_als\", maxiters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TUCKER_ALS**: Decreased maxiters.\n",
    "\n",
    "`tucker_als`'s default parameters are:\n",
    "- **stoptol** = 1e-4\n",
    "- **maxiters** = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"tucker_als\", maxiters=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HOSVD**: Increasing tol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"hosvd\", label=\"1e-3tol\", tol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Profiling Output with ***gprof2dot***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating all algorithms' profiling images\n",
    " \n",
    "The cell bellow will generate all profiling images for all algorithms in `./gprof2dot_images/<specific_algorithm>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_all_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a single algorithm's profiling images\n",
    " \n",
    "`/pstats_files/<specific_algorithm>/*.pstats` profiling images are generated to `/gprof2dot_images/<specific_algorithm>` by running the following command in Terminal <u>from within the `/profiling` directory</u>:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "algorithm=<specific_algorithm_name>\n",
    "mkdir -p gprof2dot_images/${algorithm}\n",
    "for file in pstats_files/${algorithm}/*.pstats; do\n",
    "    gprof2dot -f pstats $file \\\n",
    "        | dot -Tpng -o gprof2dot_images/${algorithm}/$(basename $file .pstats).png\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Based on [***gprof2dot*** instructions](https://nesi.github.io/perf-training/python-scatter/profiling-cprofile).**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
