{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CP_APR, CP_ALS, HOSVD, & TUCKER_ALS Profiling Visualization with gprof2dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import glob\n",
    "import os\n",
    "import pstats\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from pyttb import cp_als, cp_apr, hosvd, import_data, sptensor, tensor, tucker_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_algorithm_func(algorithm_name: str) -> Optional[Callable]:\n",
    "    \"\"\"\n",
    "    Returns the corresponding function for the user-supplied algorithm name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    algorithm_name:\n",
    "        The algorithm to profile: 'cp_apr', 'cp_als', 'tucker_als', or 'hosvd'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    alg_func:\n",
    "        The function corresponding to the algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    # input validation\n",
    "    func_handler = {\n",
    "        \"cp_apr\": cp_apr,\n",
    "        \"cp_als\": cp_als,\n",
    "        \"tucker_als\": tucker_als,\n",
    "        \"hosvd\": hosvd,\n",
    "    }\n",
    "\n",
    "    alg_func = func_handler.get(algorithm_name.lower())\n",
    "    if alg_func is None:\n",
    "        raise ValueError(f\"'{algorithm_name}' is not a recognized algorithm.\")\n",
    "    return alg_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_alg(\n",
    "    alg_func: Callable,\n",
    "    input_tensor: Union[sptensor, tensor],\n",
    "    test_file: str,\n",
    "    algorithm_name: str,\n",
    "    **params: Optional[Dict[str, Union[int, float]]],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Profiles the performance of the specified algorithm and prints the statistics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alg_func:\n",
    "        The function to profile.\n",
    "    input_tensor:\n",
    "        The input data tensor provided to the alg_func.\n",
    "    test_file:\n",
    "        The name of the tensor file.\n",
    "    algorithm_name:\n",
    "        The name of the user-supplied algorithm.\n",
    "    params:\n",
    "        Paramters passed to the algorithm function.\n",
    "        'rank' may be given to the CP algorithms; 'tol' and 'verbosity' to hosvd.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize a cProfile object and start collecting profiling data.\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "\n",
    "    alg_func(input_tensor, **params)\n",
    "\n",
    "    # stop collecting data, and send data to Stats object and sort\n",
    "    profiler.disable()\n",
    "\n",
    "    # save profiling ouput to sub-directory specific to the function being tested.\n",
    "    output_directory = f\"./pstats_files/{alg_func.__name__}\"\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)  # create directory if it doesn't exist\n",
    "\n",
    "    # from 'foo_tensor_10_4.tns' obtain 'foo_tensor_10_4'\n",
    "    tf_basename_without_tns_ext = os.path.basename(test_file).split(\".\")[0]\n",
    "    output_file = (\n",
    "        f\"{output_directory}/{tf_basename_without_tns_ext}_{algorithm_name}.pstats\"\n",
    "    )\n",
    "\n",
    "    # write profiling results to new file in output_directory.\n",
    "    profiler.dump_stats(output_file)\n",
    "\n",
    "    print(\n",
    "        f\"Profiling stats for '{algorithm_name}' on '{os.path.basename(test_file)}' saved to '{output_file}'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(\n",
    "    test_files: List[str],\n",
    "    ranks: List[int],\n",
    "    algorithm_name: str,\n",
    "    **params: Optional[Dict[str, Union[int, float]]],\n",
    "):\n",
    "    \"\"\"\n",
    "    Profiles the performance of the cp and Tucker algorithms with a set of tensors from test_files and ranks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_files:\n",
    "        A list of strings representing the file paths to the test tensors.\n",
    "    ranks:\n",
    "        A list of integers representing the tensor testing ranks.\n",
    "    algorithm_name:\n",
    "        The algorithm to profile. Should be either 'cp_apr' or 'cp_als'.\n",
    "    params:\n",
    "        Paramters passed to the algorithm function.\n",
    "        'rank' may be given to the CP algorithms; 'tol' and 'verbosity' to hosvd.\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain the appropriate function.\n",
    "    alg_func = get_algorithm_func(algorithm_name)\n",
    "\n",
    "    # choose only 'integer' files for cp_apr.\n",
    "    if algorithm_name == \"cp_apr\":\n",
    "        test_files = [tf for tf in test_files if \"integer\" in tf]\n",
    "    # TODO: bypassing a \"TypeError: unsupported operand type(s) for ** or pow(): 'sptensor' and 'int'.\"\n",
    "    if algorithm_name == \"hosvd\":\n",
    "        test_files = [tf for tf in test_files if \"sparse\" not in tf]\n",
    "\n",
    "    for test_file in test_files:\n",
    "        print(\"*\" * 80)\n",
    "        try:\n",
    "            input_tensor = import_data(test_file)  # Load the tensor.\n",
    "            if algorithm_name != \"hosvd\":\n",
    "                # test across ranks for non-hosvd algos, since hosvd doesn't accept 'rank'.\n",
    "                for rank in ranks:\n",
    "                    # load the rank parameter to the testing algorithm's params\n",
    "                    params[\"rank\"] = rank\n",
    "                    profile_alg(\n",
    "                        alg_func, input_tensor, test_file, algorithm_name, **params\n",
    "                    )\n",
    "            else:\n",
    "                profile_alg(alg_func, input_tensor, test_file, algorithm_name, **params)\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error when testing {os.path.basename(test_file)} for Algorithm = {algorithm_name}: {type(e).__name__}: {e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [2, 3, 4]\n",
    "test_files = glob.glob(\"data/*.tns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"cp_apr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"cp_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"tucker_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"hosvd\", tol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CP_APR**: Decreased stoptol, increased maxiters and maxinneriters, and differing input algorithms.\n",
    "\n",
    "`cp_apr`'s default parameters are:\n",
    "- **algorithm** = \"mu\"\n",
    "- **stoptol** = 1e-4\n",
    "- **maxiters** = 1000\n",
    "- **maxinneriters** = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(\n",
    "    test_files,\n",
    "    ranks,\n",
    "    \"cp_apr\",\n",
    "    algorithm=\"mu\",\n",
    "    stoptol=1e-5,\n",
    "    maxiters=1200,\n",
    "    maxinneriters=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(\n",
    "    test_files,\n",
    "    ranks,\n",
    "    \"cp_apr\",\n",
    "    algorithm=\"pdnr\",\n",
    "    stoptol=1e-5,\n",
    "    maxiters=2000,\n",
    "    maxinneriters=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(\n",
    "    test_files,\n",
    "    ranks,\n",
    "    \"cp_apr\",\n",
    "    algorithm=\"pqnr\",\n",
    "    stoptol=1e-5,\n",
    "    maxiters=2000,\n",
    "    maxinneriters=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CP_ALS**: Decreased stoptol, increased maxiters.\n",
    "`cp_als`'s default parameters are:\n",
    "- **stoptol** = 1e-4\n",
    "- **maxiters** = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"cp_als\", stoptol=1e-5, maxiters=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TUCKER_ALS**: Decreased stoptol, increased maxiters.\n",
    "\n",
    "`tucker_als`'s default parameters are:\n",
    "- **stoptol** = 1e-4\n",
    "- **maxiters** = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"tucker_als\", stoptol=1e-5, maxiters=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HOSVD**: Decreasing tol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile(test_files, ranks, \"hosvd\", tol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Profiling Output with ***gprof2dot***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a single algorithm's profiling images\n",
    " \n",
    "`/pstats_files/<specific_algorithm>/*.pstats` images are generated to `/gprof2dot_images/<specific_algorithm>` by running the following command in Terminal from within the `/profiling` directory:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "algorithm=<specific_algorithm_name>\n",
    "mkdir -p gprof2dot_images/${algorithm}\n",
    "for file in pstats_files/${algorithm}/*.pstats; do\n",
    "    gprof2dot -f pstats $file \\\n",
    "        | dot -Tpng -o gprof2dot_images/${algorithm}/$(basename $file .pstats).png\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Based on [***gprof2dot*** instructions](https://nesi.github.io/perf-training/python-scatter/profiling-cprofile).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
